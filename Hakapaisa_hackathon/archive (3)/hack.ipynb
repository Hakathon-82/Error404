{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('weather_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>campus_id</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>apparent_temperature</th>\n",
       "      <th>air_temperature</th>\n",
       "      <th>dew_point_temperature</th>\n",
       "      <th>relative_humidity</th>\n",
       "      <th>wind_speed</th>\n",
       "      <th>wind_direction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2018-01-01 00:00:00</td>\n",
       "      <td>16.6</td>\n",
       "      <td>16.2</td>\n",
       "      <td>13.5</td>\n",
       "      <td>84.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>142.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2018-01-01 00:01:00</td>\n",
       "      <td>17.2</td>\n",
       "      <td>16.1</td>\n",
       "      <td>13.6</td>\n",
       "      <td>85.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>134.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>2018-01-01 00:02:00</td>\n",
       "      <td>16.9</td>\n",
       "      <td>16.1</td>\n",
       "      <td>13.6</td>\n",
       "      <td>85.0</td>\n",
       "      <td>1.8</td>\n",
       "      <td>130.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>2018-01-01 00:03:00</td>\n",
       "      <td>16.9</td>\n",
       "      <td>16.1</td>\n",
       "      <td>13.6</td>\n",
       "      <td>85.0</td>\n",
       "      <td>1.8</td>\n",
       "      <td>130.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>2018-01-01 00:04:00</td>\n",
       "      <td>16.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>13.5</td>\n",
       "      <td>85.0</td>\n",
       "      <td>5.4</td>\n",
       "      <td>129.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   campus_id            timestamp  apparent_temperature  air_temperature  \\\n",
       "0          1  2018-01-01 00:00:00                  16.6             16.2   \n",
       "1          1  2018-01-01 00:01:00                  17.2             16.1   \n",
       "2          1  2018-01-01 00:02:00                  16.9             16.1   \n",
       "3          1  2018-01-01 00:03:00                  16.9             16.1   \n",
       "4          1  2018-01-01 00:04:00                  16.0             16.0   \n",
       "\n",
       "   dew_point_temperature  relative_humidity  wind_speed  wind_direction  \n",
       "0                   13.5               84.0         3.6           142.0  \n",
       "1                   13.6               85.0         0.0           134.0  \n",
       "2                   13.6               85.0         1.8           130.0  \n",
       "3                   13.6               85.0         1.8           130.0  \n",
       "4                   13.5               85.0         5.4           129.0  "
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns=['campus_id', 'dew_point_temperature'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>apparent_temperature</th>\n",
       "      <th>air_temperature</th>\n",
       "      <th>relative_humidity</th>\n",
       "      <th>wind_speed</th>\n",
       "      <th>wind_direction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018-01-01 00:00:00</td>\n",
       "      <td>16.6</td>\n",
       "      <td>16.2</td>\n",
       "      <td>84.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>142.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018-01-01 00:01:00</td>\n",
       "      <td>17.2</td>\n",
       "      <td>16.1</td>\n",
       "      <td>85.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>134.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018-01-01 00:02:00</td>\n",
       "      <td>16.9</td>\n",
       "      <td>16.1</td>\n",
       "      <td>85.0</td>\n",
       "      <td>1.8</td>\n",
       "      <td>130.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2018-01-01 00:03:00</td>\n",
       "      <td>16.9</td>\n",
       "      <td>16.1</td>\n",
       "      <td>85.0</td>\n",
       "      <td>1.8</td>\n",
       "      <td>130.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2018-01-01 00:04:00</td>\n",
       "      <td>16.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>5.4</td>\n",
       "      <td>129.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7396515</th>\n",
       "      <td>2022-04-30 21:30:00</td>\n",
       "      <td>7.5</td>\n",
       "      <td>9.7</td>\n",
       "      <td>88.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7396516</th>\n",
       "      <td>2022-04-30 22:00:00</td>\n",
       "      <td>7.4</td>\n",
       "      <td>9.3</td>\n",
       "      <td>90.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7396517</th>\n",
       "      <td>2022-04-30 22:30:00</td>\n",
       "      <td>7.5</td>\n",
       "      <td>9.4</td>\n",
       "      <td>89.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7396518</th>\n",
       "      <td>2022-04-30 23:00:00</td>\n",
       "      <td>7.7</td>\n",
       "      <td>9.2</td>\n",
       "      <td>94.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7396519</th>\n",
       "      <td>2022-04-30 23:30:00</td>\n",
       "      <td>7.6</td>\n",
       "      <td>9.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7396520 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   timestamp  apparent_temperature  air_temperature  \\\n",
       "0        2018-01-01 00:00:00                  16.6             16.2   \n",
       "1        2018-01-01 00:01:00                  17.2             16.1   \n",
       "2        2018-01-01 00:02:00                  16.9             16.1   \n",
       "3        2018-01-01 00:03:00                  16.9             16.1   \n",
       "4        2018-01-01 00:04:00                  16.0             16.0   \n",
       "...                      ...                   ...              ...   \n",
       "7396515  2022-04-30 21:30:00                   7.5              9.7   \n",
       "7396516  2022-04-30 22:00:00                   7.4              9.3   \n",
       "7396517  2022-04-30 22:30:00                   7.5              9.4   \n",
       "7396518  2022-04-30 23:00:00                   7.7              9.2   \n",
       "7396519  2022-04-30 23:30:00                   7.6              9.0   \n",
       "\n",
       "         relative_humidity  wind_speed  wind_direction  \n",
       "0                     84.0         3.6           142.0  \n",
       "1                     85.0         0.0           134.0  \n",
       "2                     85.0         1.8           130.0  \n",
       "3                     85.0         1.8           130.0  \n",
       "4                     85.0         5.4           129.0  \n",
       "...                    ...         ...             ...  \n",
       "7396515               88.0         NaN             NaN  \n",
       "7396516               90.0         NaN             NaN  \n",
       "7396517               89.0         NaN             NaN  \n",
       "7396518               94.0         NaN             NaN  \n",
       "7396519               99.0         NaN             NaN  \n",
       "\n",
       "[7396520 rows x 6 columns]"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 7396520 entries, 0 to 7396519\n",
      "Data columns (total 6 columns):\n",
      " #   Column                Dtype  \n",
      "---  ------                -----  \n",
      " 0   timestamp             object \n",
      " 1   apparent_temperature  float64\n",
      " 2   air_temperature       float64\n",
      " 3   relative_humidity     float64\n",
      " 4   wind_speed            float64\n",
      " 5   wind_direction        float64\n",
      "dtypes: float64(5), object(1)\n",
      "memory usage: 338.6+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "timestamp                   0\n",
       "apparent_temperature        0\n",
       "air_temperature             0\n",
       "relative_humidity           0\n",
       "wind_speed              59267\n",
       "wind_direction          59986\n",
       "dtype: int64"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna(subset=['wind_speed', 'wind_direction','timestamp'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>apparent_temperature</th>\n",
       "      <th>air_temperature</th>\n",
       "      <th>relative_humidity</th>\n",
       "      <th>wind_speed</th>\n",
       "      <th>wind_direction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018-01-01 00:00:00</td>\n",
       "      <td>16.6</td>\n",
       "      <td>16.2</td>\n",
       "      <td>84.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>142.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018-01-01 00:01:00</td>\n",
       "      <td>17.2</td>\n",
       "      <td>16.1</td>\n",
       "      <td>85.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>134.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018-01-01 00:02:00</td>\n",
       "      <td>16.9</td>\n",
       "      <td>16.1</td>\n",
       "      <td>85.0</td>\n",
       "      <td>1.8</td>\n",
       "      <td>130.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2018-01-01 00:03:00</td>\n",
       "      <td>16.9</td>\n",
       "      <td>16.1</td>\n",
       "      <td>85.0</td>\n",
       "      <td>1.8</td>\n",
       "      <td>130.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2018-01-01 00:04:00</td>\n",
       "      <td>16.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>5.4</td>\n",
       "      <td>129.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7386706</th>\n",
       "      <td>2021-01-14 03:36:00</td>\n",
       "      <td>16.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>18.4</td>\n",
       "      <td>225.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7386707</th>\n",
       "      <td>2021-01-14 03:37:00</td>\n",
       "      <td>15.6</td>\n",
       "      <td>19.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>20.5</td>\n",
       "      <td>215.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7386708</th>\n",
       "      <td>2021-01-14 03:38:00</td>\n",
       "      <td>16.2</td>\n",
       "      <td>18.9</td>\n",
       "      <td>63.0</td>\n",
       "      <td>16.6</td>\n",
       "      <td>218.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7386709</th>\n",
       "      <td>2021-01-14 03:39:00</td>\n",
       "      <td>15.4</td>\n",
       "      <td>18.9</td>\n",
       "      <td>63.0</td>\n",
       "      <td>20.5</td>\n",
       "      <td>225.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7386710</th>\n",
       "      <td>2021-01-14 03:40:00</td>\n",
       "      <td>14.5</td>\n",
       "      <td>19.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>25.9</td>\n",
       "      <td>204.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7336534 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   timestamp  apparent_temperature  air_temperature  \\\n",
       "0        2018-01-01 00:00:00                  16.6             16.2   \n",
       "1        2018-01-01 00:01:00                  17.2             16.1   \n",
       "2        2018-01-01 00:02:00                  16.9             16.1   \n",
       "3        2018-01-01 00:03:00                  16.9             16.1   \n",
       "4        2018-01-01 00:04:00                  16.0             16.0   \n",
       "...                      ...                   ...              ...   \n",
       "7386706  2021-01-14 03:36:00                  16.0             19.0   \n",
       "7386707  2021-01-14 03:37:00                  15.6             19.0   \n",
       "7386708  2021-01-14 03:38:00                  16.2             18.9   \n",
       "7386709  2021-01-14 03:39:00                  15.4             18.9   \n",
       "7386710  2021-01-14 03:40:00                  14.5             19.0   \n",
       "\n",
       "         relative_humidity  wind_speed  wind_direction  \n",
       "0                     84.0         3.6           142.0  \n",
       "1                     85.0         0.0           134.0  \n",
       "2                     85.0         1.8           130.0  \n",
       "3                     85.0         1.8           130.0  \n",
       "4                     85.0         5.4           129.0  \n",
       "...                    ...         ...             ...  \n",
       "7386706               63.0        18.4           225.0  \n",
       "7386707               63.0        20.5           215.0  \n",
       "7386708               63.0        16.6           218.0  \n",
       "7386709               63.0        20.5           225.0  \n",
       "7386710               63.0        25.9           204.0  \n",
       "\n",
       "[7336534 rows x 6 columns]"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "526f85\n"
     ]
    }
   ],
   "source": [
    "import hashlib\n",
    "data = \"7336534\"\n",
    "reduced_data = hashlib.md5(data.encode()).hexdigest()[:6]  # First 6 chars of hash\n",
    "print(reduced_data)  # Example: '5a4f3d'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_temperature(text):\n",
    "    L = []\n",
    "    for i in ast.literal_eval(text):\n",
    "        L.append(i['temperature'])\n",
    "    return L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>apparent_temperature</th>\n",
       "      <th>air_temperature</th>\n",
       "      <th>relative_humidity</th>\n",
       "      <th>wind_speed</th>\n",
       "      <th>wind_direction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018-01-01 00:00:00</td>\n",
       "      <td>16.6</td>\n",
       "      <td>16.2</td>\n",
       "      <td>84.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>142.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018-01-01 00:01:00</td>\n",
       "      <td>17.2</td>\n",
       "      <td>16.1</td>\n",
       "      <td>85.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>134.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018-01-01 00:02:00</td>\n",
       "      <td>16.9</td>\n",
       "      <td>16.1</td>\n",
       "      <td>85.0</td>\n",
       "      <td>1.8</td>\n",
       "      <td>130.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2018-01-01 00:03:00</td>\n",
       "      <td>16.9</td>\n",
       "      <td>16.1</td>\n",
       "      <td>85.0</td>\n",
       "      <td>1.8</td>\n",
       "      <td>130.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2018-01-01 00:04:00</td>\n",
       "      <td>16.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>5.4</td>\n",
       "      <td>129.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7386706</th>\n",
       "      <td>2021-01-14 03:36:00</td>\n",
       "      <td>16.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>18.4</td>\n",
       "      <td>225.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7386707</th>\n",
       "      <td>2021-01-14 03:37:00</td>\n",
       "      <td>15.6</td>\n",
       "      <td>19.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>20.5</td>\n",
       "      <td>215.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7386708</th>\n",
       "      <td>2021-01-14 03:38:00</td>\n",
       "      <td>16.2</td>\n",
       "      <td>18.9</td>\n",
       "      <td>63.0</td>\n",
       "      <td>16.6</td>\n",
       "      <td>218.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7386709</th>\n",
       "      <td>2021-01-14 03:39:00</td>\n",
       "      <td>15.4</td>\n",
       "      <td>18.9</td>\n",
       "      <td>63.0</td>\n",
       "      <td>20.5</td>\n",
       "      <td>225.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7386710</th>\n",
       "      <td>2021-01-14 03:40:00</td>\n",
       "      <td>14.5</td>\n",
       "      <td>19.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>25.9</td>\n",
       "      <td>204.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7336534 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   timestamp  apparent_temperature  air_temperature  \\\n",
       "0        2018-01-01 00:00:00                  16.6             16.2   \n",
       "1        2018-01-01 00:01:00                  17.2             16.1   \n",
       "2        2018-01-01 00:02:00                  16.9             16.1   \n",
       "3        2018-01-01 00:03:00                  16.9             16.1   \n",
       "4        2018-01-01 00:04:00                  16.0             16.0   \n",
       "...                      ...                   ...              ...   \n",
       "7386706  2021-01-14 03:36:00                  16.0             19.0   \n",
       "7386707  2021-01-14 03:37:00                  15.6             19.0   \n",
       "7386708  2021-01-14 03:38:00                  16.2             18.9   \n",
       "7386709  2021-01-14 03:39:00                  15.4             18.9   \n",
       "7386710  2021-01-14 03:40:00                  14.5             19.0   \n",
       "\n",
       "         relative_humidity  wind_speed  wind_direction  \n",
       "0                     84.0         3.6           142.0  \n",
       "1                     85.0         0.0           134.0  \n",
       "2                     85.0         1.8           130.0  \n",
       "3                     85.0         1.8           130.0  \n",
       "4                     85.0         5.4           129.0  \n",
       "...                    ...         ...             ...  \n",
       "7386706               63.0        18.4           225.0  \n",
       "7386707               63.0        20.5           215.0  \n",
       "7386708               63.0        16.6           218.0  \n",
       "7386709               63.0        20.5           225.0  \n",
       "7386710               63.0        25.9           204.0  \n",
       "\n",
       "[7336534 rows x 6 columns]"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "timestamp               0\n",
       "apparent_temperature    0\n",
       "air_temperature         0\n",
       "relative_humidity       0\n",
       "wind_speed              0\n",
       "wind_direction          0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(6)"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(0)"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['apparent_temperature'] = pd.to_numeric(df['apparent_temperature'], errors='coerce')\n",
    "df['air_temperature'] = pd.to_numeric(df['air_temperature'], errors='coerce')\n",
    "df['relative_humidity'] = pd.to_numeric(df['relative_humidity'], errors='coerce')\n",
    "df['wind_speed'] = pd.to_numeric(df['wind_speed'], errors='coerce')\n",
    "df['wind_direction'] = pd.to_numeric(df['wind_direction'], errors='coerce')\n",
    "df['timestamp'] = pd.to_datetime(df['timestamp'], errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_data = df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing Data:\n",
      "timestamp               0\n",
      "apparent_temperature    0\n",
      "air_temperature         0\n",
      "relative_humidity       0\n",
      "wind_speed              0\n",
      "wind_direction          0\n",
      "dtype: int64\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\"Missing Data:\\n{missing_data}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ashwi\\AppData\\Local\\Temp\\ipykernel_2368\\1281576530.py:1: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df['apparent_temperature'].fillna(df['apparent_temperature'].mean(), inplace=True)\n",
      "C:\\Users\\ashwi\\AppData\\Local\\Temp\\ipykernel_2368\\1281576530.py:2: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df['air_temperature'].fillna(df['air_temperature'].mean(), inplace=True)\n",
      "C:\\Users\\ashwi\\AppData\\Local\\Temp\\ipykernel_2368\\1281576530.py:3: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df['relative_humidity'].fillna(df['relative_humidity'].mean(), inplace=True)\n",
      "C:\\Users\\ashwi\\AppData\\Local\\Temp\\ipykernel_2368\\1281576530.py:4: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df['wind_speed'].fillna(df['wind_speed'].mean(), inplace=True)\n",
      "C:\\Users\\ashwi\\AppData\\Local\\Temp\\ipykernel_2368\\1281576530.py:5: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df['wind_direction'].fillna(df['wind_direction'].mean(), inplace=True)\n"
     ]
    }
   ],
   "source": [
    "df['apparent_temperature'].fillna(df['apparent_temperature'].mean(), inplace=True)\n",
    "df['air_temperature'].fillna(df['air_temperature'].mean(), inplace=True)\n",
    "df['relative_humidity'].fillna(df['relative_humidity'].mean(), inplace=True)\n",
    "df['wind_speed'].fillna(df['wind_speed'].mean(), inplace=True)\n",
    "df['wind_direction'].fillna(df['wind_direction'].mean(), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna(subset=['apparent_temperature'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "z_scores = np.abs(stats.zscore(df[['apparent_temperature', 'air_temperature', 'relative_humidity', 'wind_speed', 'wind_direction']]))\n",
    "df = df[(z_scores < 3).all(axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "Q1 = df[['apparent_temperature', 'air_temperature', 'relative_humidity', 'wind_speed', 'wind_direction']].quantile(0.25)\n",
    "Q3 = df[['apparent_temperature', 'air_temperature', 'relative_humidity', 'wind_speed', 'wind_direction']].quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "df = df[~((df[['apparent_temperature', 'air_temperature', 'relative_humidity', 'wind_speed', 'wind_direction']] < (Q1 - 1.5 * IQR)) | \n",
    "          (df[['apparent_temperature', 'air_temperature', 'relative_humidity', 'wind_speed', 'wind_direction']] > (Q3 + 1.5 * IQR))).any(axis=1)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['hour'] = df['timestamp'].dt.hour\n",
    "df['day_of_week'] = df['timestamp'].dt.dayofweek\n",
    "df['month'] = df['timestamp'].dt.month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop('timestamp', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ashwi\\AppData\\Local\\Temp\\ipykernel_2368\\1277559549.py:1: FutureWarning: errors='ignore' is deprecated and will raise in a future version. Use to_numeric without passing `errors` and catch exceptions explicitly instead\n",
      "  df = df.apply(pd.to_numeric, errors='ignore')\n"
     ]
    }
   ],
   "source": [
    "df = df.apply(pd.to_numeric, errors='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(500000, 8)\n"
     ]
    }
   ],
   "source": [
    "# Load the data (replace with your actual file path)\n",
    "df = pd.read_csv('weather_data.csv')\n",
    "\n",
    "# Keep only the first 500,000 rows\n",
    "df_reduced = df[:500000]\n",
    "\n",
    "# Verify the size of the new data\n",
    "print(df_reduced.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>campus_id</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>apparent_temperature</th>\n",
       "      <th>air_temperature</th>\n",
       "      <th>dew_point_temperature</th>\n",
       "      <th>relative_humidity</th>\n",
       "      <th>wind_speed</th>\n",
       "      <th>wind_direction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2018-01-01 00:00:00</td>\n",
       "      <td>16.6</td>\n",
       "      <td>16.2</td>\n",
       "      <td>13.5</td>\n",
       "      <td>84.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>142.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2018-01-01 00:01:00</td>\n",
       "      <td>17.2</td>\n",
       "      <td>16.1</td>\n",
       "      <td>13.6</td>\n",
       "      <td>85.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>134.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>2018-01-01 00:02:00</td>\n",
       "      <td>16.9</td>\n",
       "      <td>16.1</td>\n",
       "      <td>13.6</td>\n",
       "      <td>85.0</td>\n",
       "      <td>1.8</td>\n",
       "      <td>130.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>2018-01-01 00:03:00</td>\n",
       "      <td>16.9</td>\n",
       "      <td>16.1</td>\n",
       "      <td>13.6</td>\n",
       "      <td>85.0</td>\n",
       "      <td>1.8</td>\n",
       "      <td>130.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>2018-01-01 00:04:00</td>\n",
       "      <td>16.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>13.5</td>\n",
       "      <td>85.0</td>\n",
       "      <td>5.4</td>\n",
       "      <td>129.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7396515</th>\n",
       "      <td>5</td>\n",
       "      <td>2022-04-30 21:30:00</td>\n",
       "      <td>7.5</td>\n",
       "      <td>9.7</td>\n",
       "      <td>7.8</td>\n",
       "      <td>88.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7396516</th>\n",
       "      <td>5</td>\n",
       "      <td>2022-04-30 22:00:00</td>\n",
       "      <td>7.4</td>\n",
       "      <td>9.3</td>\n",
       "      <td>7.7</td>\n",
       "      <td>90.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7396517</th>\n",
       "      <td>5</td>\n",
       "      <td>2022-04-30 22:30:00</td>\n",
       "      <td>7.5</td>\n",
       "      <td>9.4</td>\n",
       "      <td>7.7</td>\n",
       "      <td>89.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7396518</th>\n",
       "      <td>5</td>\n",
       "      <td>2022-04-30 23:00:00</td>\n",
       "      <td>7.7</td>\n",
       "      <td>9.2</td>\n",
       "      <td>8.3</td>\n",
       "      <td>94.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7396519</th>\n",
       "      <td>5</td>\n",
       "      <td>2022-04-30 23:30:00</td>\n",
       "      <td>7.6</td>\n",
       "      <td>9.0</td>\n",
       "      <td>8.9</td>\n",
       "      <td>99.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7396520 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         campus_id            timestamp  apparent_temperature  \\\n",
       "0                1  2018-01-01 00:00:00                  16.6   \n",
       "1                1  2018-01-01 00:01:00                  17.2   \n",
       "2                1  2018-01-01 00:02:00                  16.9   \n",
       "3                1  2018-01-01 00:03:00                  16.9   \n",
       "4                1  2018-01-01 00:04:00                  16.0   \n",
       "...            ...                  ...                   ...   \n",
       "7396515          5  2022-04-30 21:30:00                   7.5   \n",
       "7396516          5  2022-04-30 22:00:00                   7.4   \n",
       "7396517          5  2022-04-30 22:30:00                   7.5   \n",
       "7396518          5  2022-04-30 23:00:00                   7.7   \n",
       "7396519          5  2022-04-30 23:30:00                   7.6   \n",
       "\n",
       "         air_temperature  dew_point_temperature  relative_humidity  \\\n",
       "0                   16.2                   13.5               84.0   \n",
       "1                   16.1                   13.6               85.0   \n",
       "2                   16.1                   13.6               85.0   \n",
       "3                   16.1                   13.6               85.0   \n",
       "4                   16.0                   13.5               85.0   \n",
       "...                  ...                    ...                ...   \n",
       "7396515              9.7                    7.8               88.0   \n",
       "7396516              9.3                    7.7               90.0   \n",
       "7396517              9.4                    7.7               89.0   \n",
       "7396518              9.2                    8.3               94.0   \n",
       "7396519              9.0                    8.9               99.0   \n",
       "\n",
       "         wind_speed  wind_direction  \n",
       "0               3.6           142.0  \n",
       "1               0.0           134.0  \n",
       "2               1.8           130.0  \n",
       "3               1.8           130.0  \n",
       "4               5.4           129.0  \n",
       "...             ...             ...  \n",
       "7396515         NaN             NaN  \n",
       "7396516         NaN             NaN  \n",
       "7396517         NaN             NaN  \n",
       "7396518         NaN             NaN  \n",
       "7396519         NaN             NaN  \n",
       "\n",
       "[7396520 rows x 8 columns]"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(columns=['campus_id', 'dew_point_temperature'], errors='ignore')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['timestamp'] = pd.to_datetime(df['timestamp'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('weather_data.csv') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'timestamp' not in df.columns:\n",
    "    raise KeyError(\"The 'timestamp' column is missing from the dataset.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if data['timestamp'].isnull().any():\n",
    "    print(\"Warning: Some rows have invalid or missing datetime values. Dropping these rows.\")\n",
    "    data = data.dropna(subset=['timestamp'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['timestamp'] = pd.to_datetime(df['timestamp'], errors='coerce')  # Handle invalid values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['hour'] = df['timestamp'].dt.hour\n",
    "df['month'] = df['timestamp'].dt.month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            timestamp  hour  month\n",
      "0 2018-01-01 00:00:00     0      1\n",
      "1 2018-01-01 00:01:00     0      1\n",
      "2 2018-01-01 00:02:00     0      1\n",
      "3 2018-01-01 00:03:00     0      1\n",
      "4 2018-01-01 00:04:00     0      1\n"
     ]
    }
   ],
   "source": [
    "print(df[['timestamp', 'hour', 'month']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 500000 entries, 0 to 499999\n",
      "Data columns (total 10 columns):\n",
      " #   Column                 Non-Null Count   Dtype         \n",
      "---  ------                 --------------   -----         \n",
      " 0   campus_id              500000 non-null  int64         \n",
      " 1   timestamp              500000 non-null  datetime64[ns]\n",
      " 2   apparent_temperature   500000 non-null  float64       \n",
      " 3   air_temperature        500000 non-null  float64       \n",
      " 4   dew_point_temperature  500000 non-null  float64       \n",
      " 5   relative_humidity      500000 non-null  float64       \n",
      " 6   wind_speed             496002 non-null  float64       \n",
      " 7   wind_direction         495947 non-null  float64       \n",
      " 8   hour                   500000 non-null  int32         \n",
      " 9   month                  500000 non-null  int32         \n",
      "dtypes: datetime64[ns](1), float64(6), int32(2), int64(1)\n",
      "memory usage: 34.3 MB\n"
     ]
    }
   ],
   "source": [
    "data.info(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 7396520 entries, 0 to 7396519\n",
      "Data columns (total 10 columns):\n",
      " #   Column                 Dtype         \n",
      "---  ------                 -----         \n",
      " 0   campus_id              int64         \n",
      " 1   timestamp              datetime64[ns]\n",
      " 2   apparent_temperature   float64       \n",
      " 3   air_temperature        float64       \n",
      " 4   dew_point_temperature  float64       \n",
      " 5   relative_humidity      float64       \n",
      " 6   wind_speed             float64       \n",
      " 7   wind_direction         float64       \n",
      " 8   hour                   int32         \n",
      " 9   month                  int32         \n",
      "dtypes: datetime64[ns](1), float64(6), int32(2), int64(1)\n",
      "memory usage: 507.9 MB\n",
      "Cleaned Data:\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(f\"Cleaned Data:\\n{df.info()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "df_scaled = df[['apparent_temperature', 'air_temperature', 'relative_humidity', 'wind_speed']]\n",
    "df_scaled = scaler.fit_transform(df_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('cleaned_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('cleaned_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(500000, 10)\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('cleaned_data.csv')  # Replace with your actual file path\n",
    "\n",
    "# Randomly sample 500,000 rows\n",
    "df = df.sample(n=500000, random_state=42)  # random_state ensures reproducibility\n",
    "\n",
    "# Save the reduced dataset to a new CSV file (optional)\n",
    "df.to_csv('cleaned_data.csv', index=False)\n",
    "\n",
    "# Verify the shape of the new data\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 500000 entries, 5464223 to 1983748\n",
      "Data columns (total 10 columns):\n",
      " #   Column                 Non-Null Count   Dtype  \n",
      "---  ------                 --------------   -----  \n",
      " 0   campus_id              500000 non-null  int64  \n",
      " 1   timestamp              500000 non-null  object \n",
      " 2   apparent_temperature   500000 non-null  float64\n",
      " 3   air_temperature        500000 non-null  float64\n",
      " 4   dew_point_temperature  500000 non-null  float64\n",
      " 5   relative_humidity      500000 non-null  float64\n",
      " 6   wind_speed             496002 non-null  float64\n",
      " 7   wind_direction         495947 non-null  float64\n",
      " 8   hour                   500000 non-null  int64  \n",
      " 9   month                  500000 non-null  int64  \n",
      "dtypes: float64(6), int64(3), object(1)\n",
      "memory usage: 42.0+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "import pickle\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('cleaned_data.csv')  # Replace with your reduced dataset file path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists('cleaned_data.csv'):\n",
    "        raise FileNotFoundError(f\"Data file not found at {'cleaned_data.csv'}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('cleaned_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>campus_id</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>apparent_temperature</th>\n",
       "      <th>air_temperature</th>\n",
       "      <th>dew_point_temperature</th>\n",
       "      <th>relative_humidity</th>\n",
       "      <th>wind_speed</th>\n",
       "      <th>wind_direction</th>\n",
       "      <th>hour</th>\n",
       "      <th>month</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>2021-04-22 11:45:00</td>\n",
       "      <td>11.1</td>\n",
       "      <td>14.8</td>\n",
       "      <td>7.8</td>\n",
       "      <td>63.0</td>\n",
       "      <td>16.6</td>\n",
       "      <td>348.0</td>\n",
       "      <td>11</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2020-07-27 22:36:00</td>\n",
       "      <td>9.0</td>\n",
       "      <td>11.5</td>\n",
       "      <td>11.3</td>\n",
       "      <td>99.0</td>\n",
       "      <td>14.8</td>\n",
       "      <td>189.0</td>\n",
       "      <td>22</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>2019-07-27 02:08:00</td>\n",
       "      <td>9.3</td>\n",
       "      <td>9.4</td>\n",
       "      <td>9.4</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>145.0</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>2018-04-16 11:37:00</td>\n",
       "      <td>15.0</td>\n",
       "      <td>20.5</td>\n",
       "      <td>12.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>31.3</td>\n",
       "      <td>273.0</td>\n",
       "      <td>11</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>2018-10-01 07:50:00</td>\n",
       "      <td>7.3</td>\n",
       "      <td>10.4</td>\n",
       "      <td>5.8</td>\n",
       "      <td>73.0</td>\n",
       "      <td>11.2</td>\n",
       "      <td>87.0</td>\n",
       "      <td>7</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499995</th>\n",
       "      <td>4</td>\n",
       "      <td>2018-01-08 17:06:00</td>\n",
       "      <td>29.7</td>\n",
       "      <td>32.4</td>\n",
       "      <td>9.2</td>\n",
       "      <td>24.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>263.0</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499996</th>\n",
       "      <td>3</td>\n",
       "      <td>2019-09-06 07:24:00</td>\n",
       "      <td>5.7</td>\n",
       "      <td>7.7</td>\n",
       "      <td>5.8</td>\n",
       "      <td>88.0</td>\n",
       "      <td>5.4</td>\n",
       "      <td>285.0</td>\n",
       "      <td>7</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499997</th>\n",
       "      <td>1</td>\n",
       "      <td>2018-12-17 04:56:00</td>\n",
       "      <td>15.5</td>\n",
       "      <td>14.2</td>\n",
       "      <td>14.4</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>4</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499998</th>\n",
       "      <td>1</td>\n",
       "      <td>2020-08-17 22:34:00</td>\n",
       "      <td>9.4</td>\n",
       "      <td>12.2</td>\n",
       "      <td>7.3</td>\n",
       "      <td>72.0</td>\n",
       "      <td>11.2</td>\n",
       "      <td>344.0</td>\n",
       "      <td>22</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499999</th>\n",
       "      <td>2</td>\n",
       "      <td>2018-04-13 09:26:00</td>\n",
       "      <td>19.6</td>\n",
       "      <td>20.3</td>\n",
       "      <td>11.2</td>\n",
       "      <td>56.0</td>\n",
       "      <td>5.4</td>\n",
       "      <td>144.0</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>500000 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        campus_id            timestamp  apparent_temperature  air_temperature  \\\n",
       "0               3  2021-04-22 11:45:00                  11.1             14.8   \n",
       "1               1  2020-07-27 22:36:00                   9.0             11.5   \n",
       "2               3  2019-07-27 02:08:00                   9.3              9.4   \n",
       "3               1  2018-04-16 11:37:00                  15.0             20.5   \n",
       "4               2  2018-10-01 07:50:00                   7.3             10.4   \n",
       "...           ...                  ...                   ...              ...   \n",
       "499995          4  2018-01-08 17:06:00                  29.7             32.4   \n",
       "499996          3  2019-09-06 07:24:00                   5.7              7.7   \n",
       "499997          1  2018-12-17 04:56:00                  15.5             14.2   \n",
       "499998          1  2020-08-17 22:34:00                   9.4             12.2   \n",
       "499999          2  2018-04-13 09:26:00                  19.6             20.3   \n",
       "\n",
       "        dew_point_temperature  relative_humidity  wind_speed  wind_direction  \\\n",
       "0                         7.8               63.0        16.6           348.0   \n",
       "1                        11.3               99.0        14.8           189.0   \n",
       "2                         9.4              100.0         0.0           145.0   \n",
       "3                        12.0               58.0        31.3           273.0   \n",
       "4                         5.8               73.0        11.2            87.0   \n",
       "...                       ...                ...         ...             ...   \n",
       "499995                    9.2               24.0        13.0           263.0   \n",
       "499996                    5.8               88.0         5.4           285.0   \n",
       "499997                   14.4              100.0         0.0            27.0   \n",
       "499998                    7.3               72.0        11.2           344.0   \n",
       "499999                   11.2               56.0         5.4           144.0   \n",
       "\n",
       "        hour  month  \n",
       "0         11      4  \n",
       "1         22      7  \n",
       "2          2      7  \n",
       "3         11      4  \n",
       "4          7     10  \n",
       "...      ...    ...  \n",
       "499995    17      1  \n",
       "499996     7      9  \n",
       "499997     4     12  \n",
       "499998    22      8  \n",
       "499999     9      4  \n",
       "\n",
       "[500000 rows x 10 columns]"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[['apparent_temperature', 'air_temperature', 'relative_humidity', \n",
    "        'wind_speed', 'wind_direction']]  # Features\n",
    "y = df[['hour', 'month']]  # Use both 'hour' and 'month' as target variables (if needed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = GradientBoostingRegressor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "apparent_temperature    0\n",
      "air_temperature         0\n",
      "relative_humidity       0\n",
      "wind_speed              0\n",
      "wind_direction          0\n",
      "dtype: int64\n",
      "hour     0\n",
      "month    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Check if any NaN values are present in X or y\n",
    "print(X.isna().sum())  # To see the count of NaN values in each feature\n",
    "print(y.isna().sum())  # To see the count of NaN values in the target variable\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X.dropna()\n",
    "y = y.loc[X.index]  # Ensure y matches X's rows after dropping NaN values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "imputer = SimpleImputer(strategy='mean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = imputer.fit_transform(X)\n",
    "y = imputer.fit_transform(y)  # If you have NaNs in y as well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df[['hour', 'month']]  # Replace with the actual target column names\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(500000, 2)\n"
     ]
    }
   ],
   "source": [
    "print(y.shape)  # This should print (396757, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = GradientBoostingRegressor(n_estimators=100, learning_rate=0.1, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [],
   "source": [
    "multi_target_model = MultiOutputRegressor(base_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = 'path/to/your/directory/cleaned_data.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(os.path.dirname(file_path), exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import GradientBoostingRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[['apparent_temperature', 'air_temperature', 'relative_humidity', 'wind_speed', 'wind_direction']]\n",
    "y = df['hour']  # Select the correct target column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "apparent_temperature       0\n",
      "air_temperature            0\n",
      "relative_humidity          0\n",
      "wind_speed              3998\n",
      "wind_direction          4053\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(X.isnull().sum())  # Count NaNs in each column of X\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X.dropna()\n",
    "y = y.loc[X.index]  # Ensure y matches the filtered X\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "imputer = SimpleImputer(strategy='mean')  # Replace 'mean' with 'median' if desired\n",
    "X = pd.DataFrame(imputer.fit_transform(X), columns=X.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "campus_id                0\n",
       "timestamp                0\n",
       "apparent_temperature     0\n",
       "air_temperature          0\n",
       "dew_point_temperature    0\n",
       "relative_humidity        0\n",
       "wind_direction           0\n",
       "hour                     0\n",
       "month                    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 274,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = GradientBoostingRegressor(n_estimators=100, learning_rate=0.1, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MultiOutputRegressor(base_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define features (X) and targets (y)\n",
    "X = df[['apparent_temperature', 'air_temperature', 'relative_humidity', 'wind_direction']]\n",
    "y = df[['hour', 'month']]  # Include both target columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (396757, 4)\n",
      "y_train shape: (396757, 2)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Check shapes\n",
    "print(\"X_train shape:\", X_train.shape)\n",
    "print(\"y_train shape:\", y_train.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "# Initialize base model\n",
    "base_model = GradientBoostingRegressor(n_estimators=100, learning_rate=0.1, random_state=42)\n",
    "\n",
    "# Wrap with MultiOutputRegressor\n",
    "model = MultiOutputRegressor(base_model)\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predict on test data\n",
    "predictions = model.predict(X_test)\n",
    "\n",
    "# Extract individual predictions\n",
    "hour_predictions = predictions[:, 0]  # First column: hour\n",
    "month_predictions = predictions[:, 1]  # Second column: month\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# If y is a single-column structure, reshape it\n",
    "if len(y.shape) == 1:\n",
    "    y = np.expand_dims(y, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure y is a DataFrame with two columns\n",
    "if isinstance(y, pd.Series):\n",
    "    y = pd.DataFrame(y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['campus_id', 'timestamp', 'apparent_temperature', 'air_temperature',\n",
      "       'dew_point_temperature', 'relative_humidity', 'wind_direction', 'hour',\n",
      "       'month'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(df.columns)  # Check for 'hour' and 'month' columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['timestamp'] = pd.to_datetime(df['timestamp'], errors='coerce')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [],
   "source": [
    "if df['timestamp'].isna().any():\n",
    "    print(\"Invalid or missing timestamp values found.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna(subset=['timestamp'])  # Drop rows with NaT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['hour'] = df['timestamp'].dt.hour\n",
    "df['month'] = df['timestamp'].dt.month\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(396757, 2)\n"
     ]
    }
   ],
   "source": [
    "print(y_train.shape)  # Should be (n_samples, 2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(495947, 2)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "y = np.squeeze(y)  # Removes dimensions of size 1\n",
    "print(y.shape)  # Should now be (495947, 2) if you're working with two target columns\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_y = pd.DataFrame(y, columns=['hour', 'month'])  # Replace with actual column names\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('cleaned_data.csv', 'wb') as f:\n",
    "    pickle.dump(model, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved to cleaned_data.csv\n"
     ]
    }
   ],
   "source": [
    "print(f\"Model saved to {'cleaned_data.csv'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    # Path to your dataset CSV file\n",
    "    data_file = \"temperature_data.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "train_temperature_model(data_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "# Initialize base regressor\n",
    "base_model = GradientBoostingRegressor(n_estimators=100, learning_rate=0.1, random_state=42)\n",
    "\n",
    "# Wrap with MultiOutputRegressor\n",
    "model = MultiOutputRegressor(base_model)\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predict\n",
    "predictions = model.predict(X_test)\n",
    "hour_predictions = predictions[:, 0]  # First column: hour\n",
    "month_predictions = predictions[:, 1]  # Second column: month\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved successfully.\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "\n",
    "# Example dataset\n",
    "data = pd.DataFrame({\n",
    "    \"feature1\": [1, 2, 3, 4, 5],\n",
    "    \"feature2\": [5, 4, 3, 2, 1],\n",
    "    \"target\": [1, 2, 3, 4, 5]\n",
    "})\n",
    "\n",
    "# Splitting into features and target\n",
    "X = data[[\"feature1\", \"feature2\"]]\n",
    "y = data[\"target\"]\n",
    "\n",
    "# Splitting into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Define and train the model\n",
    "model = GradientBoostingRegressor(n_estimators=100, learning_rate=0.1, random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Save the model\n",
    "with open('model.pkl', 'wb') as f:\n",
    "    pickle.dump(model, f)\n",
    "\n",
    "print(\"Model saved successfully.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved successfully in the current directory.\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "# Save the model directly in the current directory\n",
    "with open('model.pkl', 'wb') as f:\n",
    "    pickle.dump(model, f)\n",
    "\n",
    "print(\"Model saved successfully in the current directory.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved successfully at models\\model.pkl.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pickle\n",
    "\n",
    "# Define the target directory and file path\n",
    "save_dir = 'models'  # Change 'models' to your desired folder name\n",
    "file_path = os.path.join(save_dir, 'model.pkl')\n",
    "\n",
    "# Create the directory if it does not exist\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "# Save the model\n",
    "with open(file_path, 'wb') as f:\n",
    "    pickle.dump(model, f)\n",
    "\n",
    "print(f\"Model saved successfully at {file_path}.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory to save: models\n",
      "File path: models\\model.pkl\n"
     ]
    }
   ],
   "source": [
    "save_dir = 'models'\n",
    "print(f\"Directory to save: {save_dir}\")\n",
    "print(f\"File path: {os.path.join(save_dir, 'model.pkl')}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model object: GradientBoostingRegressor(random_state=42)\n"
     ]
    }
   ],
   "source": [
    "print(\"Model object:\", model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved successfully at models\\model.pkl.\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import os\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "import pandas as pd\n",
    "\n",
    "# Assuming your data is prepared and split into X_train and y_train\n",
    "# For example, let's create dummy data:\n",
    "# X_train = pd.DataFrame(...)  # your feature data\n",
    "# y_train = pd.DataFrame(...)  # your target data\n",
    "\n",
    "# Train a GradientBoostingRegressor model\n",
    "model = GradientBoostingRegressor(n_estimators=100, learning_rate=0.1, random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Ensure the model is trained before saving\n",
    "if model:\n",
    "    # Define the file path\n",
    "    save_dir = 'models'\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "    file_path = os.path.join(save_dir, 'model.pkl')\n",
    "\n",
    "    # Save the model using pickle\n",
    "    with open(file_path, 'wb') as f:\n",
    "        pickle.dump(model, f)\n",
    "    print(f\"Model saved successfully at {file_path}.\")\n",
    "else:\n",
    "    print(\"Model not trained. Please check the training process.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File exists and is valid: models/model.pkl\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Check if model file exists\n",
    "file_path = 'models/model.pkl'\n",
    "if os.path.exists(file_path) and os.path.getsize(file_path) > 0:\n",
    "    print(f\"File exists and is valid: {file_path}\")\n",
    "else:\n",
    "    print(f\"Error: {file_path} does not exist or is empty. Please check your model saving process.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded successfully.\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "# Define the file path\n",
    "file_path = 'models/model.pkl'\n",
    "\n",
    "try:\n",
    "    # Load the model from the file\n",
    "    with open(file_path, 'rb') as f:\n",
    "        model = pickle.load(f)\n",
    "    print(\"Model loaded successfully.\")\n",
    "except FileNotFoundError:\n",
    "    print(f\"Error: {file_path} does not exist. Please check the path.\")\n",
    "except EOFError:\n",
    "    print(f\"Error: The file at {file_path} is empty or corrupted.\")\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trained Model: GradientBoostingRegressor(random_state=42)\n"
     ]
    }
   ],
   "source": [
    "print(f\"Trained Model: {model}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved successfully at models\\model.pkl.\n",
      "Model loaded successfully.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ashwi\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\ensemble\\_gb.py:668: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)  # TODO: Is this still required?\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import os\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Creating a simple dataset for the demonstration\n",
    "X_train = pd.DataFrame(np.random.rand(100, 5), columns=['feat1', 'feat2', 'feat3', 'feat4', 'feat5'])\n",
    "y_train = pd.DataFrame(np.random.rand(100, 1), columns=['target'])\n",
    "\n",
    "# Train the model\n",
    "model = GradientBoostingRegressor(n_estimators=100, learning_rate=0.1, random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Save the trained model\n",
    "save_dir = 'models'\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "file_path = os.path.join(save_dir, 'model.pkl')\n",
    "\n",
    "# Ensure the model is trained and then save it\n",
    "if model:\n",
    "    with open(file_path, 'wb') as f:\n",
    "        pickle.dump(model, f)\n",
    "    print(f\"Model saved successfully at {file_path}.\")\n",
    "\n",
    "# Load the model\n",
    "try:\n",
    "    with open(file_path, 'rb') as f:\n",
    "        loaded_model = pickle.load(f)\n",
    "    print(\"Model loaded successfully.\")\n",
    "except FileNotFoundError:\n",
    "    print(f\"Error: {file_path} does not exist. Please check the path.\")\n",
    "except EOFError:\n",
    "    print(f\"Error: The file at {file_path} is empty or corrupted.\")\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
